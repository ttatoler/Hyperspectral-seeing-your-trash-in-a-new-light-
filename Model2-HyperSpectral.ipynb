{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4fa7a8e-6a6a-40a5-9256-9fd7df5fb52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, ColorJitter, RandomHorizontalFlip, RandomRotation\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tifffile\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"background\", \"film\", \"basket\", \"cardboard\", \"video_tape\", \"filament\", \"bag\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Define which classes to ignore in evaluation (only background)\n",
    "ignore_in_eval = [True, False, False, False, False, False, False]\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fba514-1808-4003-ba05-d105065a2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths using relative paths\n",
    "import os\n",
    "\n",
    "# Set up base directory (assumes the script/notebook is in the Hackathon folder)\n",
    "base_dir = \".\"\n",
    "\n",
    "# Define dataset paths\n",
    "train_img_dir = os.path.join(base_dir, \"hyper\", \"train\")\n",
    "train_mask_dir = os.path.join(base_dir, \"labels_hyper_lt\", \"train\")\n",
    "val_img_dir = os.path.join(base_dir, \"hyper\", \"val\")\n",
    "val_mask_dir = os.path.join(base_dir, \"labels_hyper_lt\", \"val\")\n",
    "\n",
    "# Define transformations\n",
    "train_mask_transform = Compose([\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomRotation(degrees=20)\n",
    "])\n",
    "\n",
    "val_mask_transform = Compose([])  # No transformation for validation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb91a0f-20f6-4699-9813-e86e79a492af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, hyper_dir, mask_dir, image_transform=None, mask_transform=None):\n",
    "        self.hyper_dir = hyper_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.num_bands = 33  # Default value, will be updated after loading first image\n",
    "        \n",
    "        # Check if directories exist\n",
    "        if not os.path.exists(hyper_dir):\n",
    "            print(f\"Warning: Hyperspectral directory not found: {hyper_dir}\")\n",
    "            self.image_filenames = []\n",
    "        else:\n",
    "            # Get and check image filenames - include all common image extensions\n",
    "            self.image_filenames = sorted([\n",
    "                f for f in os.listdir(hyper_dir) \n",
    "                if any(f.lower().endswith(ext) for ext in ['.tif', '.tiff', '.TIF', '.TIFF'])\n",
    "            ])\n",
    "            print(f\"Found {len(self.image_filenames)} hyperspectral images in {hyper_dir}\")\n",
    "        \n",
    "        if not os.path.exists(mask_dir):\n",
    "            print(f\"Warning: Mask directory not found: {mask_dir}\")\n",
    "            self.mask_filenames = []\n",
    "        else:\n",
    "            # Get and check mask filenames\n",
    "            self.mask_filenames = sorted([\n",
    "                f for f in os.listdir(mask_dir) \n",
    "                if any(f.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.PNG', '.JPG', '.JPEG', '.BMP'])\n",
    "            ])\n",
    "            print(f\"Found {len(self.mask_filenames)} masks in {mask_dir}\")\n",
    "        \n",
    "        # Ensure same number of images and masks\n",
    "        if len(self.image_filenames) != len(self.mask_filenames):\n",
    "            print(\"Warning: Number of images and masks doesn't match!\")\n",
    "            if len(self.image_filenames) == 0 or len(self.mask_filenames) == 0:\n",
    "                print(\"Critical: One of the directories is empty while the other has files!\")\n",
    "                if len(self.image_filenames) == 0:\n",
    "                    print(f\"Image directory ({hyper_dir}) appears to be empty or has no supported files\")\n",
    "                if len(self.mask_filenames) == 0:\n",
    "                    print(f\"Mask directory ({mask_dir}) appears to be empty or has no supported files\")\n",
    "            else:\n",
    "                min_len = min(len(self.image_filenames), len(self.mask_filenames))\n",
    "                self.image_filenames = self.image_filenames[:min_len]\n",
    "                self.mask_filenames = self.mask_filenames[:min_len]\n",
    "                print(f\"Using the first {min_len} files from each directory\")\n",
    "        \n",
    "        # Check first image to get band count\n",
    "        if len(self.image_filenames) > 0:\n",
    "            sample_path = os.path.join(hyper_dir, self.image_filenames[0])\n",
    "            try:\n",
    "                image = tifffile.imread(sample_path)\n",
    "                if len(image.shape) == 3 and image.shape[-1] > 3:\n",
    "                    self.num_bands = image.shape[-1]\n",
    "                elif len(image.shape) == 3:\n",
    "                    self.num_bands = image.shape[0]\n",
    "                else:\n",
    "                    print(f\"Warning: Unexpected image shape {image.shape}, defaulting to 33 bands\")\n",
    "                print(f\"Detected {self.num_bands} spectral bands\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading sample image: {str(e)}\")\n",
    "                print(f\"Defaulting to {self.num_bands} bands\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.hyper_dir, self.image_filenames[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
    "        \n",
    "        try:\n",
    "            image = tifffile.imread(img_path).astype(np.float32)\n",
    "            image = torch.tensor(image, dtype=torch.float32) / 255.0\n",
    "            \n",
    "            if len(image.shape) == 3 and image.shape[-1] > 3:\n",
    "                image = image.permute(2, 0, 1)\n",
    "            \n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "            mask_np = np.array(mask, dtype=np.uint8)\n",
    "            \n",
    "            _, height, width = image.shape\n",
    "            if mask_np.shape[0] != height or mask_np.shape[1] != width:\n",
    "                mask = mask.resize((width, height), Image.NEAREST)\n",
    "                mask_np = np.array(mask, dtype=np.uint8)\n",
    "            \n",
    "            mask_tensor = torch.tensor(mask_np, dtype=torch.long)\n",
    "            \n",
    "            if self.image_transform:\n",
    "                for i in range(image.shape[0]):\n",
    "                    band = image[i]\n",
    "                    band_min = band.min()\n",
    "                    band_max = band.max()\n",
    "                    if band_min != band_max:\n",
    "                        image[i] = (band - band_min) / (band_max - band_min)\n",
    "                    else:\n",
    "                        image[i] = torch.zeros_like(band)\n",
    "            \n",
    "            if self.mask_transform:\n",
    "                seed = torch.randint(0, 2**32, (1,)).item()\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                mask_pil = Image.fromarray(mask_np)\n",
    "                mask_pil = self.mask_transform(mask_pil)\n",
    "                mask_tensor = torch.tensor(np.array(mask_pil), dtype=torch.long)\n",
    "            \n",
    "            return image, mask_tensor\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data at index {idx}, paths: {img_path}, {mask_path}\")\n",
    "            print(f\"Error details: {str(e)}\")\n",
    "            num_bands = getattr(self, 'num_bands', 33)\n",
    "            dummy_image = torch.zeros((num_bands, 256, 256), dtype=torch.float)\n",
    "            dummy_mask = torch.zeros((256, 256), dtype=torch.long)\n",
    "            return dummy_image, dummy_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98526cd-e9a7-4f5b-9319-479a8ba6b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=8):\n",
    "        super(SpectralAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Calculate reduced channels with a minimum to avoid extremely small values\n",
    "        reduced_channels = max(in_channels // reduction_ratio, 1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, reduced_channels, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(reduced_channels, in_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get dimensions\n",
    "        b, c, _, _ = x.size()\n",
    "        \n",
    "        # Spatial pooling\n",
    "        y = self.avg_pool(x)\n",
    "        \n",
    "        # Reshape for FC layers\n",
    "        y = y.view(b, c)\n",
    "        \n",
    "        # Apply FC layers\n",
    "        y = self.fc(y)\n",
    "        \n",
    "        # Reshape back to spatial form\n",
    "        y = y.view(b, c, 1, 1)\n",
    "        \n",
    "        # Channel-wise multiplication (attention mechanism)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f59c1c1-b150-4c60-acb3-f084680537a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "class PretrainedHyperspectralUNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(PretrainedHyperspectralUNet, self).__init__()\n",
    "        \n",
    "        # Spectral Attention to focus on important bands\n",
    "        self.spectral_attention = SpectralAttention(in_channels)\n",
    "        \n",
    "        # Spectral reduction layer to map from hyperspectral (33 bands) to RGB (3 bands)\n",
    "        self.spectral_reduction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 3, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        # Load pre-trained ResNet34 encoder\n",
    "        self.encoder = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Get ResNet layers for skip connections\n",
    "        self.initial = nn.Sequential(\n",
    "            self.encoder.conv1,  # 3 -> 64\n",
    "            self.encoder.bn1,\n",
    "            self.encoder.relu\n",
    "        )\n",
    "        self.maxpool = self.encoder.maxpool  # 64 -> 64\n",
    "        self.encoder1 = self.encoder.layer1  # 64 -> 64\n",
    "        self.encoder2 = self.encoder.layer2  # 64 -> 128\n",
    "        self.encoder3 = self.encoder.layer3  # 128 -> 256\n",
    "        self.encoder4 = self.encoder.layer4  # 256 -> 512\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self._decoder_block(512, 256)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self._decoder_block(256, 128)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self._decoder_block(128, 64)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = self._decoder_block(128, 64)\n",
    "        \n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "    \n",
    "    def _decoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Store input dimensions for later use\n",
    "        _, _, h, w = x.shape\n",
    "        \n",
    "        # Apply Spectral Attention to enhance important bands\n",
    "        x = self.spectral_attention(x)\n",
    "        \n",
    "        # Reduce spectral dimensions from hyperspectral to RGB\n",
    "        x = self.spectral_reduction(x)\n",
    "        \n",
    "        # Encoder\n",
    "        x1 = self.initial(x)  # 3 -> 64\n",
    "        p1 = self.maxpool(x1)  # 64 -> 64 (with maxpool)\n",
    "        \n",
    "        e1 = self.encoder1(p1)  # 64 -> 64\n",
    "        e2 = self.encoder2(e1)  # 64 -> 128\n",
    "        e3 = self.encoder3(e2)  # 128 -> 256\n",
    "        e4 = self.encoder4(e3)  # 256 -> 512\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d4 = self.upconv4(e4)  # 512 -> 256\n",
    "        d4 = torch.cat([d4, e3], dim=1)  # 256 + 256 -> 512\n",
    "        d4 = self.decoder4(d4)  # 512 -> 256\n",
    "        \n",
    "        d3 = self.upconv3(d4)  # 256 -> 128\n",
    "        d3 = torch.cat([d3, e2], dim=1)  # 128 + 128 -> 256\n",
    "        d3 = self.decoder3(d3)  # 256 -> 128\n",
    "        \n",
    "        d2 = self.upconv2(d3)  # 128 -> 64\n",
    "        d2 = torch.cat([d2, e1], dim=1)  # 64 + 64 -> 128\n",
    "        d2 = self.decoder2(d2)  # 128 -> 64\n",
    "        \n",
    "        d1 = self.upconv1(d2)  # 64 -> 64\n",
    "        d1 = torch.cat([d1, x1], dim=1)  # 64 + 64 -> 128\n",
    "        d1 = self.decoder1(d1)  # 128 -> 64\n",
    "        \n",
    "        # Final convolution\n",
    "        out = self.final_conv(d1)  # 64 -> num_classes\n",
    "        \n",
    "        # Ensure output has same spatial dimensions as input (in case of dimension mismatch)\n",
    "        if out.shape[2] != h or out.shape[3] != w:\n",
    "            out = F.interpolate(out, size=(h, w), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e10b810c-af2d-47fc-84c9-695d4f543ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        inputs_soft = F.softmax(inputs, dim=1)\n",
    "        targets_onehot = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        intersection = torch.sum(inputs_soft * targets_onehot, dim=(0, 2, 3))\n",
    "        union = torch.sum(inputs_soft + targets_onehot, dim=(0, 2, 3))\n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        log_probs = F.log_softmax(inputs, dim=1)\n",
    "        probs = torch.exp(log_probs)\n",
    "        loss = (1 - probs) ** self.gamma * self.ce(inputs, targets)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe9cb03-c144-46be-8fb4-6c7536fa6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(preds, masks, num_classes):\n",
    "    \"\"\"Calculate IoU for each class and mean IoU.\"\"\"\n",
    "    intersection = torch.zeros(num_classes).to(device)\n",
    "    union = torch.zeros(num_classes).to(device)\n",
    "\n",
    "    # Count presence of each class for debugging\n",
    "    class_in_pred = [False] * num_classes\n",
    "    class_in_target = [False] * num_classes\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        if ignore_in_eval[cls]:\n",
    "            continue  # Skip background class in IoU calculation\n",
    "\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (masks == cls)\n",
    "        \n",
    "        # Check if class exists in predictions and targets\n",
    "        class_in_pred[cls] = pred_inds.any().item()\n",
    "        class_in_target[cls] = target_inds.any().item()\n",
    "\n",
    "        intersection[cls] += (pred_inds & target_inds).sum().float()\n",
    "        union[cls] += (pred_inds | target_inds).sum().float()\n",
    "\n",
    "    # Calculate IoU for each class\n",
    "    iou_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        if ignore_in_eval[cls]:\n",
    "            iou_per_class.append(float('nan'))  # Mark background class as NaN\n",
    "        else:\n",
    "            if union[cls] > 0:\n",
    "                iou = intersection[cls] / union[cls]\n",
    "                iou_per_class.append(iou.item())\n",
    "            else:\n",
    "                # If class is not present in either prediction or ground truth\n",
    "                iou_per_class.append(float('nan'))\n",
    "\n",
    "    # Compute mean IoU excluding background and classes not present\n",
    "    valid_ious = [iou for iou in iou_per_class if not np.isnan(iou)]\n",
    "    mean_iou = np.mean(valid_ious) if valid_ious else 0.0\n",
    "\n",
    "    return mean_iou, iou_per_class, class_in_pred, class_in_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68175e12-671d-4c15-9bcf-1a827f6b7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: If you want to ignore some classes in evaluation, define them here\n",
    "# For instance, if you have num_classes=4 and you want to ignore none:\n",
    "# ignore_in_eval = [False, False, False, False]\n",
    "# Adjust based on your project needs\n",
    "ignore_in_eval = []\n",
    "\n",
    "# Example class names; adapt to your own data\n",
    "# class_names = ['Background', 'Class1', 'Class2', 'Class3', ...]\n",
    "class_names = []\n",
    "\n",
    "def train_pretrained_hyperspectral_model():\n",
    "    # Create datasets\n",
    "    train_dataset = HyperspectralDataset(\n",
    "        hyper_dir=train_img_dir,\n",
    "        mask_dir=train_mask_dir,\n",
    "        image_transform=True,\n",
    "        mask_transform=train_mask_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = HyperspectralDataset(\n",
    "        hyper_dir=val_img_dir,\n",
    "        mask_dir=val_mask_dir,\n",
    "        image_transform=True,\n",
    "        mask_transform=val_mask_transform\n",
    "    )\n",
    "\n",
    "    # Check if datasets are empty\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(f\"Training dataset is empty. Please check paths: {train_img_dir} and {train_mask_dir}\")\n",
    "    if len(val_dataset) == 0:\n",
    "        print(\"Warning: Validation dataset is empty. Will only train without validation.\")\n",
    "\n",
    "    # Get number of bands\n",
    "    num_bands = train_dataset.num_bands\n",
    "    print(f\"Using {num_bands} spectral bands for model\")\n",
    "\n",
    "    # Create data loaders\n",
    "    batch_size = 8  # Adjust if running into memory issues\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = (\n",
    "        DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        if len(val_dataset) > 0\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # If your arrays for ignoring classes or naming them are empty, fill them based on num_classes\n",
    "    global ignore_in_eval, class_names\n",
    "    if not ignore_in_eval or len(ignore_in_eval) != num_classes:\n",
    "        ignore_in_eval = [False] * num_classes\n",
    "    if not class_names or len(class_names) != num_classes:\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "\n",
    "    # Initialize model\n",
    "    model = PretrainedHyperspectralUNet(in_channels=num_bands, num_classes=num_classes).to(device)\n",
    "    print(\"Model initialized with pre-trained ResNet34 backbone\")\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = torch.ones(num_classes).to(device)\n",
    "    class_weights[0] = 0.1  # Example of lowering the weight for background class\n",
    "\n",
    "    # Define loss function (combined Focal + Dice)\n",
    "    criterion = lambda outputs, targets: 0.5 * FocalLoss(weight=class_weights)(outputs, targets) + 0.5 * DiceLoss()(outputs, targets)\n",
    "\n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5, min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    num_epochs = 50\n",
    "    best_iou = 0.0\n",
    "    history = {'train_loss': [], 'train_iou': [], 'val_loss': [], 'val_iou': [], 'lr': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # -------------------------------\n",
    "        # Training Phase\n",
    "        # -------------------------------\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "        for images, masks in progress_bar:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # Compute training IoU\n",
    "        model.eval()\n",
    "        train_preds, train_masks = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, masks in train_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                train_preds.append(preds)\n",
    "                train_masks.append(masks)\n",
    "\n",
    "        train_preds = torch.cat(train_preds, dim=0)\n",
    "        train_masks = torch.cat(train_masks, dim=0)\n",
    "        train_mean_iou, train_iou_per_class, _, _ = calculate_iou(train_preds, train_masks, num_classes)\n",
    "        history['train_iou'].append(train_mean_iou)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Mean IoU: {train_mean_iou:.4f}\")\n",
    "        print(\"Train IoU per Class:\")\n",
    "        for cls in range(num_classes):\n",
    "            if not ignore_in_eval[cls]:\n",
    "                class_iou = train_iou_per_class[cls]\n",
    "                if not np.isnan(class_iou):\n",
    "                    print(f\"  {class_names[cls]}: {class_iou:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  {class_names[cls]}: N/A (not present)\")\n",
    "\n",
    "        # -------------------------------\n",
    "        # Validation Phase\n",
    "        # -------------------------------\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_preds, val_masks_all = [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, masks in tqdm(val_loader, desc=\"Validation\"):\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    val_preds.append(preds)\n",
    "                    val_masks_all.append(masks)\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "            val_preds = torch.cat(val_preds, dim=0)\n",
    "            val_masks_all = torch.cat(val_masks_all, dim=0)\n",
    "            val_mean_iou, val_iou_per_class, classes_in_pred, classes_in_gt = calculate_iou(\n",
    "                val_preds, val_masks_all, num_classes\n",
    "            )\n",
    "            history['val_iou'].append(val_mean_iou)\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Mean IoU: {val_mean_iou:.4f}\")\n",
    "            print(\"Validation IoU per Class:\")\n",
    "            for cls in range(num_classes):\n",
    "                if not ignore_in_eval[cls]:\n",
    "                    class_iou = val_iou_per_class[cls]\n",
    "                    if not np.isnan(class_iou):\n",
    "                        print(f\"  {class_names[cls]}: {class_iou:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"  {class_names[cls]}: N/A (not present)\")\n",
    "\n",
    "            # Classes present in predictions and ground truth\n",
    "            print(\"Classes present in predictions:\", [class_names[i] for i in range(num_classes) if classes_in_pred[i]])\n",
    "            print(\"Classes present in ground truth:\", [class_names[i] for i in range(num_classes) if classes_in_gt[i]])\n",
    "\n",
    "            # Update scheduler based on validation IoU\n",
    "            scheduler.step(val_mean_iou)\n",
    "\n",
    "            # Check for best model (based on validation IoU)\n",
    "            if val_mean_iou > best_iou:\n",
    "                print(f\"New best IoU achieved: {val_mean_iou:.4f} (previous: {best_iou:.4f})\")\n",
    "                best_iou = val_mean_iou\n",
    "                torch.save(model.state_dict(), \"best_model.pth\")\n",
    "                print(\"Best model saved!\")\n",
    "        else:\n",
    "            # If no validation set exists, we can still step the scheduler on training IoU (optional)\n",
    "            scheduler.step(train_mean_iou)\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Final Evaluation\n",
    "    # -------------------------------\n",
    "    # Load best model and do a final evaluation\n",
    "    if os.path.exists(\"best_model.pth\"):\n",
    "        print(\"Loading best model for final evaluation...\")\n",
    "        model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "    else:\n",
    "        print(\"Warning: No best_model.pth found; using last epoch model.\")\n",
    "\n",
    "    print(\"Final Model Evaluation:\")\n",
    "    if train_loader is not None:\n",
    "        evaluate_model(model, train_loader, \"Training Set\")\n",
    "    if val_loader is not None:\n",
    "        evaluate_model(model, val_loader, \"Validation Set\")\n",
    "\n",
    "    print(\"Training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "468ff44c-517a-4c67-8efe-c12860c6adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, dataset_name):\n",
    "    model.eval()\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = lambda outputs, targets: 0.5 * FocalLoss()(outputs, targets) + 0.5 * DiceLoss()(outputs, targets)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    all_preds, all_masks = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.append(preds)\n",
    "            all_masks.append(masks)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_masks = torch.cat(all_masks, dim=0)\n",
    "    mean_iou, iou_per_class, _, _ = calculate_iou(all_preds, all_masks, num_classes)\n",
    "    \n",
    "    total_loss /= len(loader.dataset)\n",
    "    print(f\"{dataset_name} Results:\")\n",
    "    print(f\"Loss: {total_loss:.4f}\")\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(\"IoU per Class:\")\n",
    "    for cls in range(num_classes):\n",
    "        if not ignore_in_eval[cls]:\n",
    "            class_iou = iou_per_class[cls]\n",
    "            if not np.isnan(class_iou):\n",
    "                print(f\"  {class_names[cls]}: {class_iou:.4f}\")\n",
    "            else:\n",
    "                print(f\"  {class_names[cls]}: N/A (not present)\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1422e0-f203-4b4c-85fa-ac647c14ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 514 hyperspectral images in .\\hyper\\train\n",
      "Found 514 masks in .\\labels_hyper_lt\\train\n",
      "Detected 256 spectral bands\n",
      "Found 167 hyperspectral images in .\\hyper\\val\n",
      "Found 167 masks in .\\labels_hyper_lt\\val\n",
      "Detected 256 spectral bands\n",
      "Using 256 spectral bands for model\n",
      "Model initialized with pre-trained ResNet34 backbone\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [03:52<00:00,  3.58s/it, loss=1.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.1947, Train Mean IoU: 0.0907\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.4308\n",
      "  Class 1: 0.0735\n",
      "  Class 2: 0.0082\n",
      "  Class 3: 0.0095\n",
      "  Class 4: 0.0152\n",
      "  Class 5: 0.0004\n",
      "  Class 6: 0.0975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:16<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Val Loss: 1.1651, Val Mean IoU: 0.0921\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.4249\n",
      "  Class 1: 0.0748\n",
      "  Class 2: 0.0204\n",
      "  Class 3: 0.0106\n",
      "  Class 4: 0.0118\n",
      "  Class 5: 0.0007\n",
      "  Class 6: 0.1014\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "New best IoU achieved: 0.0921 (previous: 0.0000)\n",
      "Best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [03:58<00:00,  3.67s/it, loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 1.1008, Train Mean IoU: 0.1071\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.5024\n",
      "  Class 1: 0.1071\n",
      "  Class 2: 0.0408\n",
      "  Class 3: 0.0030\n",
      "  Class 4: 0.0017\n",
      "  Class 5: 0.0004\n",
      "  Class 6: 0.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:16<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Val Loss: 1.0836, Val Mean IoU: 0.1047\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.4821\n",
      "  Class 1: 0.1091\n",
      "  Class 2: 0.0442\n",
      "  Class 3: 0.0042\n",
      "  Class 4: 0.0027\n",
      "  Class 5: 0.0007\n",
      "  Class 6: 0.0898\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "New best IoU achieved: 0.1047 (previous: 0.0921)\n",
      "Best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:09<00:00,  3.85s/it, loss=1.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 1.0613, Train Mean IoU: 0.1172\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.5010\n",
      "  Class 1: 0.1002\n",
      "  Class 2: 0.0761\n",
      "  Class 3: 0.0341\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:16<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Val Loss: 1.0487, Val Mean IoU: 0.1110\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.4857\n",
      "  Class 1: 0.0980\n",
      "  Class 2: 0.0693\n",
      "  Class 3: 0.0231\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1007\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "New best IoU achieved: 0.1110 (previous: 0.1047)\n",
      "Best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [03:51<00:00,  3.56s/it, loss=0.955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 1.0318, Train Mean IoU: 0.1155\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.4559\n",
      "  Class 1: 0.1240\n",
      "  Class 2: 0.1082\n",
      "  Class 3: 0.0192\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:18<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Val Loss: 1.0267, Val Mean IoU: 0.1026\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.4331\n",
      "  Class 1: 0.1193\n",
      "  Class 2: 0.0733\n",
      "  Class 3: 0.0101\n",
      "  Class 4: 0.0001\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0825\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [05:00<00:00,  4.62s/it, loss=1.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 1.0081, Train Mean IoU: 0.1156\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.4000\n",
      "  Class 1: 0.1269\n",
      "  Class 2: 0.1387\n",
      "  Class 3: 0.0557\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:23<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Val Loss: 1.0145, Val Mean IoU: 0.1022\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.3811\n",
      "  Class 1: 0.1189\n",
      "  Class 2: 0.0862\n",
      "  Class 3: 0.0575\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0720\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 5', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:13<00:00,  3.90s/it, loss=1.02] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 0.9861, Train Mean IoU: 0.1202\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.3916\n",
      "  Class 1: 0.1371\n",
      "  Class 2: 0.1423\n",
      "  Class 3: 0.0850\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:19<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Val Loss: 1.0073, Val Mean IoU: 0.1026\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.3722\n",
      "  Class 1: 0.1202\n",
      "  Class 2: 0.1087\n",
      "  Class 3: 0.0456\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0713\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:13<00:00,  3.90s/it, loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 0.9614, Train Mean IoU: 0.1524\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.5548\n",
      "  Class 1: 0.2194\n",
      "  Class 2: 0.1471\n",
      "  Class 3: 0.0145\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:17<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Val Loss: 1.0182, Val Mean IoU: 0.1274\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.5361\n",
      "  Class 1: 0.1254\n",
      "  Class 2: 0.0957\n",
      "  Class 3: 0.0334\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1010\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "New best IoU achieved: 0.1274 (previous: 0.1110)\n",
      "Best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:01<00:00,  3.72s/it, loss=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 0.9414, Train Mean IoU: 0.1544\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.5272\n",
      "  Class 1: 0.1988\n",
      "  Class 2: 0.1516\n",
      "  Class 3: 0.0870\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:14<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Val Loss: 1.0119, Val Mean IoU: 0.1276\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.5099\n",
      "  Class 1: 0.1475\n",
      "  Class 2: 0.0997\n",
      "  Class 3: 0.0504\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0861\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "New best IoU achieved: 0.1276 (previous: 0.1274)\n",
      "Best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [03:50<00:00,  3.54s/it, loss=0.917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 0.9360, Train Mean IoU: 0.1322\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.3716\n",
      "  Class 1: 0.2040\n",
      "  Class 2: 0.1241\n",
      "  Class 3: 0.1147\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:18<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Val Loss: 1.0095, Val Mean IoU: 0.1068\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.3670\n",
      "  Class 1: 0.1492\n",
      "  Class 2: 0.0934\n",
      "  Class 3: 0.0612\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0768\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:15<00:00,  3.93s/it, loss=0.968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 0.9170, Train Mean IoU: 0.1393\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.3938\n",
      "  Class 1: 0.1777\n",
      "  Class 2: 0.2214\n",
      "  Class 3: 0.0830\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:17<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Val Loss: 1.0026, Val Mean IoU: 0.0990\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.3566\n",
      "  Class 1: 0.1371\n",
      "  Class 2: 0.0842\n",
      "  Class 3: 0.0367\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0780\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:12<00:00,  3.89s/it, loss=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 0.9058, Train Mean IoU: 0.1715\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.5344\n",
      "  Class 1: 0.2479\n",
      "  Class 2: 0.1433\n",
      "  Class 3: 0.1210\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:14<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Val Loss: 1.0029, Val Mean IoU: 0.1358\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.5271\n",
      "  Class 1: 0.1587\n",
      "  Class 2: 0.1160\n",
      "  Class 3: 0.0513\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0977\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 5', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "New best IoU achieved: 0.1358 (previous: 0.1276)\n",
      "Best model saved!\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:19<00:00,  4.00s/it, loss=0.903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 0.8942, Train Mean IoU: 0.1578\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.4573\n",
      "  Class 1: 0.2322\n",
      "  Class 2: 0.1509\n",
      "  Class 3: 0.1181\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:41<00:00,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Val Loss: 0.9771, Val Mean IoU: 0.1305\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.4600\n",
      "  Class 1: 0.1723\n",
      "  Class 2: 0.1207\n",
      "  Class 3: 0.0620\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0985\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [05:33<00:00,  5.13s/it, loss=0.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 0.8848, Train Mean IoU: 0.1701\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.4903\n",
      "  Class 1: 0.2500\n",
      "  Class 2: 0.1505\n",
      "  Class 3: 0.1469\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:20<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Val Loss: 0.9984, Val Mean IoU: 0.1325\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.4900\n",
      "  Class 1: 0.1619\n",
      "  Class 2: 0.1207\n",
      "  Class 3: 0.0531\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1022\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:33<00:00,  4.22s/it, loss=1.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 0.8639, Train Mean IoU: 0.1766\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.4675\n",
      "  Class 1: 0.2976\n",
      "  Class 2: 0.1506\n",
      "  Class 3: 0.1470\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:28<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Val Loss: 0.9982, Val Mean IoU: 0.1308\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.4717\n",
      "  Class 1: 0.1500\n",
      "  Class 2: 0.1123\n",
      "  Class 3: 0.0671\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1144\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:29<00:00,  4.14s/it, loss=0.822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 0.8549, Train Mean IoU: 0.1750\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.4578\n",
      "  Class 1: 0.3136\n",
      "  Class 2: 0.1938\n",
      "  Class 3: 0.1064\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:29<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Val Loss: 1.0190, Val Mean IoU: 0.1267\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.4511\n",
      "  Class 1: 0.1417\n",
      "  Class 2: 0.1182\n",
      "  Class 3: 0.0694\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1064\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [04:31<00:00,  4.17s/it, loss=1.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 0.8535, Train Mean IoU: 0.1740\n",
      "Train IoU per Class:\n",
      "  Class 0: 0.5576\n",
      "  Class 1: 0.2530\n",
      "  Class 2: 0.1767\n",
      "  Class 3: 0.0217\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.2090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 21/21 [01:50<00:00,  5.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Val Loss: 1.0102, Val Mean IoU: 0.1310\n",
      "Validation IoU per Class:\n",
      "  Class 0: 0.5605\n",
      "  Class 1: 0.1273\n",
      "  Class 2: 0.1124\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1164\n",
      "Classes present in predictions: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 6']\n",
      "Classes present in ground truth: ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 37/65 [03:15<02:27,  5.28s/it, loss=0.815]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m train_pretrained_hyperspectral_model()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Create data loaders for evaluation\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[8], line 83\u001b[0m, in \u001b[0;36mtrain_pretrained_hyperspectral_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, masks \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[0;32m     84\u001b[0m     images, masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     86\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackathon\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackathon\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackathon\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackathon\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[3], line 91\u001b[0m, in \u001b[0;36mHyperspectralDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     89\u001b[0m band \u001b[38;5;241m=\u001b[39m image[i]\n\u001b[0;32m     90\u001b[0m band_min \u001b[38;5;241m=\u001b[39m band\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m---> 91\u001b[0m band_max \u001b[38;5;241m=\u001b[39m band\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m band_min \u001b[38;5;241m!=\u001b[39m band_max:\n\u001b[0;32m     93\u001b[0m     image[i] \u001b[38;5;241m=\u001b[39m (band \u001b[38;5;241m-\u001b[39m band_min) \u001b[38;5;241m/\u001b[39m (band_max \u001b[38;5;241m-\u001b[39m band_min)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Train the model\n",
    "    model = train_pretrained_hyperspectral_model()\n",
    "    \n",
    "    # Create data loaders for evaluation\n",
    "    try:\n",
    "        train_dataset = HyperspectralDataset(\n",
    "            hyper_dir=train_img_dir,\n",
    "            mask_dir=train_mask_dir,\n",
    "            image_transform=True,\n",
    "            mask_transform=None\n",
    "        )\n",
    "        \n",
    "        val_dataset = HyperspectralDataset(\n",
    "            hyper_dir=val_img_dir,\n",
    "            mask_dir=val_mask_dir,\n",
    "            image_transform=True,\n",
    "            mask_transform=None\n",
    "        )\n",
    "        \n",
    "        # Check if datasets are empty\n",
    "        if len(train_dataset) == 0:\n",
    "            print(\"Warning: Training dataset is empty for evaluation. Skipping training evaluation.\")\n",
    "            train_loader = None\n",
    "        else:\n",
    "            batch_size = 8\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        if len(val_dataset) == 0:\n",
    "            print(\"Warning: Validation dataset is empty for evaluation. Skipping validation evaluation.\")\n",
    "            val_loader = None\n",
    "        else:\n",
    "            batch_size = 8\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Final evaluation\n",
    "        print(\"Final Model Evaluation:\")\n",
    "        if train_loader is not None:\n",
    "            evaluate_model(model, train_loader, \"Training Set\")\n",
    "        if val_loader is not None:\n",
    "            evaluate_model(model, val_loader, \"Validation Set\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "        print(\"Skipping final evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712a297-b83e-4cd0-9175-e847fb938424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
